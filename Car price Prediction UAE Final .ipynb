{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "37a5c18a-0e05-4482-929e-9ee137bb4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b1931fc-e7e2-4830-8a6d-ece3cc7d48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress harmless warnings often triggered by specific library versions\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "918be2b5-0d5c-43d8-89c9-728dde3310bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CONFIGURATION AND DATA LOADING ---\n",
    "# NOTE: The file path below has been updated to the user's local system path.\n",
    "# This variable is now set to the specific local path.\n",
    "LOCAL_DATA_FILE_PATH = r\"C:\\Users\\unnim\\OneDrive\\Desktop\\KRISHNADEV\\DATA SCIENCE entry Elevate\\Final Project\\cars_data.csv\"\n",
    "TARGET_COLUMN = 'Price'\n",
    "MODEL_FILENAME = 'random_forest_car_predictor.joblib'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84c612cc-f789-4c54-80db-82561e4b291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features based on user request and data inspection\n",
    "# Performance is inferred from 'Cylinders'\n",
    "CATEGORICAL_FEATURES = ['Make', 'Model', 'Body Type', 'Transmission', 'Fuel Type', 'Location']\n",
    "NUMERICAL_FEATURES = ['Mileage', 'Cylinders', 'Age'] # 'Age' will be engineered\n",
    "DROP_FEATURES = ['Description', 'Color', 'Year'] # 'Year' is used to create 'Age', then dropped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "844b774c-3b05-493d-97fb-cc22fb4d4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Loads the dataset from the specified local file path.\"\"\"\n",
    "    try:\n",
    "        # Use the hardcoded local path\n",
    "        df = pd.read_csv(file_path) \n",
    "        print(f\"Data loaded successfully from: {file_path}. Initial shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at the specified path: {file_path}\")\n",
    "        print(\"Please check the path is correct and the file exists.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "81e7dbaa-4f0f-4324-ba35-1d4eacb9b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. FEATURE ENGINEERING AND PREPROCESSING ---\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Performs data cleaning, feature engineering (Age calculation),\n",
    "    and handles missing values.\n",
    "    \"\"\"\n",
    "    # 2.1 Feature Engineering: Calculate Car Age\n",
    "    current_year = datetime.now().year\n",
    "    # Convert 'Year' to numeric, handling potential errors\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "    df['Age'] = current_year - df['Year']\n",
    "\n",
    "    # 2.2 Clean Target Variable ('Price')\n",
    "    # Use IQR to remove extreme outliers in Price (helps the model generalize)\n",
    "    Q1_price = df[TARGET_COLUMN].quantile(0.05)\n",
    "    Q3_price = df[TARGET_COLUMN].quantile(0.95)\n",
    "    IQR_price = Q3_price - Q1_price\n",
    "    # Filter out values below Q1 and above Q3 (a strong filter for typical price datasets)\n",
    "    df_clean = df[\n",
    "        (df[TARGET_COLUMN] > Q1_price) & (df[TARGET_COLUMN] < Q3_price)\n",
    "    ].copy()\n",
    "    print(f\"Data cleaned. Shape after price outlier removal: {df_clean.shape}\")\n",
    "\n",
    "    # 2.3 Handle Missing Values\n",
    "\n",
    "    # --- FIX START: Ensure Cylinders is numeric before imputation and conversion ---\n",
    "    # Convert 'Cylinders' to numeric, coercing non-numeric values (like potential initial strings) to NaN\n",
    "    df_clean['Cylinders'] = pd.to_numeric(df_clean['Cylinders'], errors='coerce')\n",
    "\n",
    "    # Impute remaining missing 'Cylinders' with the mode (most common value)\n",
    "    df_clean['Cylinders'] = df_clean['Cylinders'].fillna(df_clean['Cylinders'].mode()[0])\n",
    "    \n",
    "    # For categorical features, fill NaNs with a string like 'Unknown'\n",
    "    for col in CATEGORICAL_FEATURES:\n",
    "        df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "    # Drop rows where 'Mileage' or 'Price' might still be missing or invalid\n",
    "    df_clean.dropna(subset=NUMERICAL_FEATURES + [TARGET_COLUMN], inplace=True)\n",
    "\n",
    "    # Convert 'Cylinders' to integer after successful imputation\n",
    "    df_clean['Cylinders'] = df_clean['Cylinders'].astype(int)\n",
    "    # --- FIX END ---\n",
    "     # 2.4 Select Final Features\n",
    "    features = NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
    "    X = df_clean[features]\n",
    "    y = df_clean[TARGET_COLUMN]\n",
    "\n",
    "    return X, y, features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "09beb58d-445d-4f5a-b972-182a234475bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. PIPELINE SETUP (TRANSFORMERS) ---\n",
    "\n",
    "def create_preprocessor():\n",
    "    \"\"\"Creates a ColumnTransformer for preprocessing numerical and categorical data.\"\"\"\n",
    "    # Transformer for numerical data: Scale the values (important for some models)\n",
    "    numerical_transformer = StandardScaler()\n",
    "\n",
    "    # Transformer for categorical data: One-Hot Encode (essential for nominal data)\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Create the preprocessor combining both\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, NUMERICAL_FEATURES),\n",
    "            ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "        ],\n",
    "        remainder='drop' # Drop any columns not explicitly selected\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "37598966-57a4-42f0-a1a4-b811461f8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 4. MODEL TRAINING AND EVALUATION ---\n",
    "\n",
    "def train_and_evaluate_model(X, y, preprocessor):\n",
    "    \"\"\"Splits data, trains models, evaluates, and saves the best one.\"\"\"\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"\\nTraining set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15),\n",
    "        \"LinearRegression\": LinearRegression()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    best_r2 = -np.inf\n",
    "    best_model_name = \"\"\n",
    "    best_pipeline = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training {name} ---\")\n",
    "\n",
    "        # Create the full pipeline: Preprocessing -> Model\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])\n",
    "\n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "551f1ba2-07f9-4aa5-98ad-da03be99f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. MODEL TRAINING AND EVALUATION ---\n",
    "\n",
    "def train_and_evaluate_model(X, y, preprocessor):\n",
    "    \"\"\"Splits data, trains models, evaluates, and saves the best one.\"\"\"\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"\\nTraining set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15),\n",
    "        \"LinearRegression\": LinearRegression()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    best_r2 = -np.inf\n",
    "    best_model_name = \"\"\n",
    "    best_pipeline = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training {name} ---\")\n",
    "\n",
    "        # Create the full pipeline: Preprocessing -> Model\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])\n",
    "\n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluate\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        results[name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "        print(f\"MAE (Mean Absolute Error): AED {mae:,.2f}\")\n",
    "        print(f\"RMSE (Root Mean Squared Error): AED {rmse:,.2f}\")\n",
    "        print(f\"R-squared ($R^2$): {r2:.4f}\")\n",
    "\n",
    "        # Track the best model\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_model_name = name\n",
    "            best_pipeline = pipeline\n",
    "\n",
    "    # Save the best model pipeline (FIXED INDENTATION)\n",
    "    if best_pipeline:\n",
    "        joblib.dump(best_pipeline, MODEL_FILENAME)\n",
    "        print(f\"\\n✅ Best model ({best_model_name}) saved to {MODEL_FILENAME}\")\n",
    "\n",
    "    return results, best_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "32e6db82-c379-4b45-9fb5-ca95fdfb066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. PREDICTION EXAMPLE FUNCTION ---\n",
    "\n",
    "def predict_car_price(model, new_car_data):\n",
    "    \"\"\"Uses the trained model to predict the price of a single new car.\"\"\"\n",
    "    # Create a DataFrame from the input dictionary\n",
    "    df_new = pd.DataFrame([new_car_data])\n",
    "\n",
    "    # Add the 'Age' feature, just like during training\n",
    "    current_year = datetime.now().year\n",
    "    df_new['Age'] = current_year - df_new['Year']\n",
    "    df_new.drop(columns=['Year'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Select the required features (including the new 'Age')\n",
    "    features_for_prediction = [col for col in NUMERICAL_FEATURES + CATEGORICAL_FEATURES if col != 'Year']\n",
    "    X_new = df_new[features_for_prediction]\n",
    "\n",
    "    # Make prediction\n",
    "    predicted_price = model.predict(X_new)[0]\n",
    "\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a67324a2-23ea-4999-b069-ea799b4bc1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from: C:\\Users\\unnim\\OneDrive\\Desktop\\KRISHNADEV\\DATA SCIENCE entry Elevate\\Final Project\\cars_data.csv. Initial shape: (10000, 12)\n"
     ]
    }
   ],
   "source": [
    "# --- 6. MAIN EXECUTION BLOCK ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load Data\n",
    "    # Use the local path defined at the top of the script\n",
    "    df = load_data(LOCAL_DATA_FILE_PATH)\n",
    "    if df is None:\n",
    "        # If df is None (file not found), print a clear error and exit\n",
    "        print(\"Data loading failed. Cannot proceed with preprocessing or model training.\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8f92bdd0-77e8-4c96-8f86-05859f3ae55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from: C:\\Users\\unnim\\OneDrive\\Desktop\\KRISHNADEV\\DATA SCIENCE entry Elevate\\Final Project\\cars_data.csv. Initial shape: (10000, 12)\n",
      "Data cleaned. Shape after price outlier removal: (9000, 13)\n",
      "\n",
      "Training set size: 7200, Test set size: 1800\n",
      "\n",
      "--- Training RandomForest ---\n",
      "MAE (Mean Absolute Error): AED 82,638.20\n",
      "RMSE (Root Mean Squared Error): AED 125,160.85\n",
      "R-squared ($R^2$): 0.5276\n",
      "\n",
      "--- Training LinearRegression ---\n",
      "MAE (Mean Absolute Error): AED 75,654.15\n",
      "RMSE (Root Mean Squared Error): AED 116,237.97\n",
      "R-squared ($R^2$): 0.5926\n",
      "\n",
      "✅ Best model (LinearRegression) saved to random_forest_car_predictor.joblib\n",
      "\n",
      "--- Model Demonstration ---\n",
      "Hypothetical Car Details:\n",
      "  Make: toyota\n",
      "  Model: camry\n",
      "  Year: 2021\n",
      "  Mileage: 50000\n",
      "  Body Type: Sedan\n",
      "  Cylinders: 4\n",
      "  Transmission: Automatic Transmission\n",
      "  Fuel Type: Gasoline\n",
      "  Location: Dubai\n",
      "\n",
      "💰 Predicted Price (using Random Forest): AED 27,773.19\n"
     ]
    }
   ],
   "source": [
    " # --- 6. MAIN EXECUTION BLOCK ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load Data\n",
    "    # Use the local path defined at the top of the script\n",
    "    df = load_data(LOCAL_DATA_FILE_PATH)\n",
    "    if df is None:\n",
    "        # If df is None (file not found), print a clear error and exit\n",
    "        print(\"Data loading failed. Cannot proceed with preprocessing or model training.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. Preprocess Data and Get Features\n",
    "    X, y, features = preprocess_data(df)\n",
    "\n",
    "    # 3. Create Preprocessing Pipeline (Transformer)\n",
    "    preprocessor = create_preprocessor()\n",
    "\n",
    "    # 4. Train and Evaluate Models\n",
    "    results, best_pipeline = train_and_evaluate_model(X, y, preprocessor)\n",
    "\n",
    "    # 5. Demonstration: Predict the price of a new hypothetical car\n",
    "    if best_pipeline:\n",
    "        print(\"\\n--- Model Demonstration ---\")\n",
    "        example_car = {\n",
    "            'Make': 'toyota',\n",
    "            'Model': 'camry',\n",
    "            'Year': 2021,\n",
    "            'Mileage': 50000,\n",
    "            'Body Type': 'Sedan',\n",
    "            'Cylinders': 4,\n",
    "            'Transmission': 'Automatic Transmission',\n",
    "            'Fuel Type': 'Gasoline',\n",
    "            'Location': 'Dubai'\n",
    "        }\n",
    "\n",
    "        # Predict the price\n",
    "        predicted_price = predict_car_price(best_pipeline, example_car)\n",
    "\n",
    "        print(\"Hypothetical Car Details:\")\n",
    "        for k, v in example_car.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "\n",
    "        print(f\"\\n💰 Predicted Price (using Random Forest): AED {predicted_price:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff70e1d-99f1-43ae-b1bc-831aef8f8e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
